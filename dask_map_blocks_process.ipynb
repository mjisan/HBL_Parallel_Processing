{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"Times New Roman\" style=\"font-size:24px\" color='red'> Parallel Processing of a High Resolution Surface Wind Model Data using Dask (Dask.map_blocks & Xarray)</font>\n",
    "================================================================\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/8/80/Rhode_Island_Rams_logo.svg\" \n",
    "     width=\"30%\" \n",
    "     align=right\n",
    "     alt=\"Dask logo\">\n",
    "\n",
    "\n",
    "This notebook shows application of dask-backed `xarray.DataArray` to parallelize the plotting of wind field from the University of Rhode Island's [Hurricane Boundary Layer Wind Model(URI-HBL)](https://ams.confex.com/ams/34HURR/meetingapp.cgi/Paper/373889) \n",
    "This program uses [dask.array.map_blocks](https://docs.dask.org/en/latest/generated/dask.array.map_blocks.html) to distribute chunks of data blocks within the wrapper.\n",
    "\n",
    "URI-HBL is a three-dimensional model developed primarily to improve the surface wind forecast during the landfall of hurricanes. The model uses information of actual land cover characteristincs to simulate the wind field over land. The model runs uses a vortex following moving mesh with a horizontal grid spacing of 1km x 1km and vertical resolution of 30m. The output interval of the model is every minute. The HBL model's computational architecture is based on Intel's MPI Library that allows the model to run in parallel within multiple CPU's. However, the post processing of the model data still uses C-C+ based serial programs i.e. NCL, Matlab etc.\n",
    "\n",
    "This higher spatial and temporal resolution makes it challenging to process the output from the HBL model. Current post-processing of HBL's output is based on [NCAR Command Language](http://ncl.ucar.edu/) which takes long time to process the data.\n",
    "\n",
    "This Dask based parallel program will help process the HBL's output at a faster rate and can play an important role in operational forecast of hurricane wind field.  \n",
    "\n",
    "In this exercise, we are going to explore the application of Dask; particularly [dask.delayed](http://dask.pydata.org/en/latest/delayed.html) to parallelize the processing of HBL outputs. In doing so, we are going to use the following libraries: \n",
    "\n",
    "(a) [Dask](https://dask.org/)\n",
    "\n",
    "(b) [Numpy](https://numpy.org/)\n",
    "\n",
    "(c) [xarray](http://xarray.pydata.org/en/stable/)\n",
    "\n",
    "(d) [Matplotlib](https://matplotlib.org/)\n",
    "\n",
    "(e) [Pandas](https://pandas.pydata.org/)\n",
    "\n",
    "(f) [cartopy](https://scitools.org.uk/cartopy/docs/latest/)\n",
    "\n",
    "(g) [Geocat](https://geocat.ucar.edu/)\n",
    "\n",
    "(h) [IPython](https://ipython.org/)\n",
    "\n",
    "(i) [FFmpeg](https://github.com/kkroening/ffmpeg-python)\n",
    "\n",
    "(j) [graphviz](https://graphviz.org/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"Times New Roman\" style=\"font-size:24px\"> Case Study: Hurricane Michael (2018) </font>\n",
    "\n",
    "<img src=\"http://uri-hurricanes.info/michael_track.png\" \n",
    "     width=\"45%\" \n",
    "     align=right\n",
    "     alt=\"michael-track\">\n",
    "\n",
    "\n",
    "\n",
    "This exercise will use the HBL simulated outputs for the case of Hurricane Michael (2018). We will be plotting the surface wind speed calcualted from the U and V-wind components.\n",
    "\n",
    "Two sample datasets provided with this exercise; one for [u-wind component](http://tds.renci.org:8080/thredds/dodsC/dhs-crc-unc/HURRICANE_MICHAEL/michael_regrid_ucomp_30min.nc) and another one is for [v-wind component](http://tds.renci.org:8080/thredds/dodsC/dhs-crc-unc/HURRICANE_MICHAEL/michael_regrid_vcomp_30min.nc).\n",
    "\n",
    "The datasets have been subsetted at 30-minutes interval for this exercise. \n",
    "[NCAR Command Language](http://ncl.ucar.edu/) took 308.241 seconds CPU time to process this data. We will experiment whether parallelization using Dask.map_blocks and Xarray DataArray  can process this data faster! \n",
    ".\n",
    "\n",
    ".\n",
    "using 30 workers, dask.map_blocks was able to process the same data in 70 seconds CPU time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"Times New Roman\" style=\"font-size:24px\" color='red'> Start Dask Client and Set up Cluster </font>\n",
    "   <font style=\"Times New Roman\" style=\"font-size:18px\" color='blue'> Client is used to view the dashboard and cluster is used to distribute the job across multiple processors</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_jobqueue\n",
    "import dask.distributed\n",
    "\n",
    "cluster = dask_jobqueue.SLURMCluster(cores=1, memory='100GB',queue='lowpri')\n",
    "cluster.scale(30) \n",
    "client = dask.distributed.Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Wrapper module which will be passed to the Dask's map_blocks function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper(nparray, plot_wind, dim, block_info=None, **kwargs):\n",
    "    \n",
    "    import xarray as xr\n",
    "\n",
    "    index = block_info[None]['chunk-location'][-1]\n",
    "    \n",
    "    coords = kwargs.get('coords')\n",
    "    dims = kwargs.get('dims')\n",
    "    attrs = kwargs.get('attrs')\n",
    "    \n",
    "    if coords:\n",
    "        coords = coords.to_dataset().isel({dim: index}).coords\n",
    "    \n",
    "    xr_array = xr.DataArray(nparray.squeeze(),\n",
    "                            dims=set(da.dims)-set([dim]),\n",
    "                            coords=coords,\n",
    "                            attrs=da.attrs)\n",
    "\n",
    "    plot_wind(xr_array, index) \n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def sequence(da, dim, plot_wind):\n",
    "     \n",
    "    import dask.array as darray\n",
    "    assert isinstance(da, xr.DataArray)\n",
    "    \n",
    "    if da.dims[-1] != dim:\n",
    "        not_dim = list(set(list(da.dims)) - set([dim])) + [dim]\n",
    "        da = da.transpose(*not_dim)\n",
    "    assert(da.data.chunksize[-1] == 1)\n",
    "    \n",
    "    mapblock = darray.map_blocks(wrapper,\n",
    "                               da.data,\n",
    "                               drop_axis=(0,1),  \n",
    "                               chunks=(1,),  \n",
    "                               dtype=np.float64, \n",
    "                               dim=dim,  \n",
    "                               dims=da.dims, coords=da.coords, attrs=da.attrs, \n",
    "                               plot_wind=plot_wind)\n",
    "    \n",
    "    return mapblock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"Times New Roman\" style=\"font-size:24px\" color='red'> Getting familiar with data </font>\n",
    "   <font style=\"Times New Roman\" style=\"font-size:18px\" color='blue'> Datasets are stored in an OPeNDAP server </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "nlat = 1100\n",
    "nlon = 1100\n",
    "ntime = 48\n",
    "\n",
    "%time du = xr.open_dataset(\"http://tds.renci.org:8080/thredds/dodsC/dhs-crc-unc/HURRICANE_MICHAEL/michael_regrid_ucomp_30min.nc\").isel(time=slice(None, 48))\n",
    "%time dv = xr.open_dataset(\"http://tds.renci.org:8080/thredds/dodsC/dhs-crc-unc/HURRICANE_MICHAEL/michael_regrid_vcomp_30min.nc\").isel(time=slice(None, 48))\n",
    "\n",
    "du1 = du.u10\n",
    "dv1 = dv.v10\n",
    "\n",
    "wspd1 = np.sqrt(du1**2+dv1**2)\n",
    "\n",
    "wspd = wspd1.rename({'lati':'lat','loni':'lon'})\n",
    "\n",
    "\n",
    "wspd['lat'].attrs['long_name'] = 'latitude'\n",
    "wspd['lat'].attrs['units'] = 'degrees_north'\n",
    "wspd['lon'].attrs['long_name'] = 'longitude'\n",
    "wspd['lon'].attrs['units'] = 'degrees_east'\n",
    "wspd2 = wspd.transpose(\"lat\", \"lon\", \"time\")\n",
    "lat = wspd2['lat']\n",
    "lon = wspd2['lon']\n",
    "\n",
    "\n",
    "db = (xr.DataArray(np.array(wspd2), \n",
    "                  dims=['lat', 'lon', 'time'],\n",
    "                  coords={'lat':wspd2['lat'], 'lon':wspd2['lon'], 'time': pd.date_range('2018-10-10 00:00:00', freq='30min', periods=ntime)})\n",
    "      .chunk({'time': 1}))\n",
    "\n",
    "db['lat'].attrs['long_name'] = 'latitude'\n",
    "db['lat'].attrs['units'] = 'degrees_north'\n",
    "db['lon'].attrs['long_name'] = 'longitude'\n",
    "db['lon'].attrs['units'] = 'degrees_east'\n",
    "da = db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That dataset must have `chunksize=1` on the dimension over which to animate. If our intent is to make a movie that animates in `time`, we should chunk as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@dask.delayed\n",
    "def make_plot(xr_array, index):\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib as mpl\n",
    "    import cartopy\n",
    "    import cartopy.crs as ccrs\n",
    "    import cartopy.feature as cfeature\n",
    "    from geocat.viz import cmaps as gvcmaps\n",
    "    from geocat.viz import util as gvutil\n",
    "    \n",
    "    f, ax = plt.subplots(1, 1, figsize=(15,12))\n",
    "\n",
    "    projection = ccrs.PlateCarree()\n",
    "    \n",
    "    ax = plt.axes(projection=projection)\n",
    "    plt.title(\"\")\n",
    "    projection = ccrs.PlateCarree()\n",
    "    ax = plt.axes(projection=projection)\n",
    "    ax.add_feature(cfeature.LAND, facecolor='white')\n",
    "    ax.tick_params(labelsize=12)\n",
    "    ax.set_title('',fontsize=12)\n",
    "    gvutil.set_axes_limits_and_ticks(ax,\n",
    "                                    xticks=[-100, -96, -92, -88,  -84, -80, -76],\n",
    "                                    yticks=[14,  18,  22,  26,  30,  34])\n",
    "\n",
    "    gvutil.add_lat_lon_ticklabels(ax)\n",
    "\n",
    "    gvutil.add_major_minor_ticks(ax,\n",
    "                                 x_minor_per_major=2,\n",
    "                                 y_minor_per_major=2,\n",
    "                                 labelsize=12)\n",
    "\n",
    "    gvutil.set_titles_and_labels(ax,\n",
    "                             maintitle=\" \",\n",
    "                             maintitlefontsize=14,\n",
    "                             lefttitle=\" \",\n",
    "                             lefttitlefontsize=8,\n",
    "                             righttitle=\"Hurricane Michael (2018)\",\n",
    "                             righttitlefontsize=8,\n",
    "                             xlabel=\"Longitude\",\n",
    "                             ylabel=\"Latitude\")\n",
    "\n",
    "    ax.add_feature(cartopy.feature.COASTLINE)\n",
    "    ax.add_feature(cartopy.feature.BORDERS)\n",
    "    ax.add_feature(cartopy.feature.LAND)\n",
    "    ax.coastlines(resolution='10m', color='black', linewidth=0.25)\n",
    "    ax.add_feature(ccrs.cartopy.feature.STATES, linewidth=0.25)\n",
    "    ax.coastlines(linewidths=1.5)\n",
    "    ax.set_extent([-100, -78, 20, 35], crs=ccrs.PlateCarree())\n",
    "    ax.xaxis.set_tick_params(labelsize=12)\n",
    "    ax.yaxis.set_tick_params(labelsize=12)\n",
    "    ax.add_feature(cfeature.LAND, facecolor='white')\n",
    "    ax.set_extent([-90, -77, 23.5, 34.5], crs=ccrs.PlateCarree())\n",
    "    ax.xaxis.set_tick_params(labelsize=12)\n",
    "    ax.yaxis.set_tick_params(labelsize=12)\n",
    "    ax.add_feature(cfeature.LAND, facecolor='white')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # ax=ax is required!\n",
    "    xr_array.plot(ax=ax,\n",
    "                  vmin=0, vmax=60, cmap=mpl.cm.jet, \n",
    "                  extend='both',\n",
    "                  cbar_kwargs={'orientation': 'vertical'})\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('')\n",
    "   \n",
    "    f.savefig(f\"images2/{index:04d}.png\", dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # this prevents a warning that is issued when more than 20 figures are open.\n",
    "    # maybe it saves memory too?\n",
    "    plt.close(f)\n",
    "    del f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del du1\n",
    "del dv1\n",
    "del wspd1\n",
    "del wspd\n",
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call 'sequence' which will return dask array, dimension over which the loop will be executed and the plotting module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapblock = sequence(da=da, dim='time', plot_wind=make_plot)\n",
    "mapblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapblock.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://static1.srcdn.com/wordpress/wp-content/uploads/2020/05/Toy-Story-Buzz-Woody.jpg\" \n",
    "     width=\"50%\" \n",
    "     align=left\n",
    "     alt=\"Dask logo\">\n",
    "\n",
    "\n",
    "\n",
    "<font style=\"Times New Roman\" style=\"font-size:36px\" color='red'> Parallel Distribution !</font>\n",
    "================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%time dask.compute(mapblock[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"Times New Roman\" style=\"font-size:24px\" color='red'> Let's check the number of output files. </font>\n",
    "   <font style=\"Times New Roman\" style=\"font-size:18px\" color='blue'> It should be 48 since variable 'time' has length of 48 and we are plotting for each time interval</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $PWD/images2 | wc -l                 #bash command to check number of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -alh images2/                         #list the output files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"Times New Roman\" style=\"font-size:24px\" color='red'> Display one of the plots </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('images2/0000.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"Times New Roman\" style=\"font-size:24px\" color='red'> Use ImageMagick to make animated GIF from the sequence of PNGs </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! /usr/bin/convert -delay 14 -loop 0 /projects/ees/dhs-crc/mjisan/NCL_HBL/CTD/a11_nc_ctd/GEOCAT/FINAL_VERSIONS/images2/*.png -scale 1000x1000 animation2.gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image('animation2.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"Times New Roman\" style=\"font-size:24px\" color='red'> Final Thoughts </font>\n",
    "\n",
    "\n",
    "\n",
    "- The dask.map_blocks and dask parallel program helped distributing the plotting function as well as xr.DataArray within multiple CPU's which significantly reduced the processing time.\n",
    "\n",
    "\n",
    "- Although this approach took slightly longer time than the dask.delayed function, it was able to distribute chunks of data within different CPU's enabling the efficient handling of large data. \n",
    "\n",
    "<font style=\"Times New Roman\" style=\"font-size:24px\" color='blue'>This simple Dask-backed xr.DataArray and plotting function works 6 times faster than the current NCL & Matlab program!</font>\n",
    "================================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"Times New Roman\" style=\"font-size:24px\" color='red'> Acknowledgements </font>\n",
    "\n",
    "- [Pangeo discourse forum](https://discourse.pangeo.io/)\n",
    "\n",
    "- [Dask Social](https://docs.dask.org/en/stable/support.html)\n",
    "\n",
    "- [Deepak Cherian's Github Repo](https://github.com/dcherian)\n"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "parallel-animations.ipynb",
    "public": true
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
